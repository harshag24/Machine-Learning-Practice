{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1c-VyHFMsHGZ-cL6JSW5YinP6jaxF-4uN",
      "authorship_tag": "ABX9TyMr2NdIVG6qXkPT8E8lH20A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshag24/Tensorflow-Practice/blob/master/tf_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSW7DVH13cTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk8pgbwqea07",
        "colab_type": "text"
      },
      "source": [
        "Neural Network Example \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeUPhR3Obkgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_mnist = keras.datasets.mnist # load dataset\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = num_mnist.load_data()  # split into tetsing and training\n",
        "\n",
        "class_names = ['0', '1', '2', '3', '4',\n",
        "               '5', '6', '7', '8', '9']\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),  # input layer (1)\n",
        "    keras.layers.Dense(128, activation='relu'),  # hidden layer (2)\n",
        "    keras.layers.Dense(64 , activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax') # output layer (3)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)  # we pass the data, labels and epochs and watch the magic!\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1) \n",
        "\n",
        "print('Test accuracy:', test_acc , \"Test Loss\",test_loss)\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "for i in range(0,251):\n",
        "  print(\"Prediction for \",i,\"is\",np.argmax(predictions[i]))\n",
        "  print(\"Expected \",test_labels[i])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7_lUBMQefqZ",
        "colab_type": "text"
      },
      "source": [
        "Covolutional Neural Network example on pretrained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXgu-BNDGWAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wha6fGmkenEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "(training_set, validation_set), dataset_info = tfds.load(\n",
        "    'tf_flowers', \n",
        "    with_info=True, \n",
        "    as_supervised=True, \n",
        "    split=['train[:70%]', 'train[70%:]'],\n",
        ")\n",
        "\n",
        "num_classes = dataset_info.features['label'].num_classes\n",
        "\n",
        "num_training_examples = 0\n",
        "num_validation_examples = 0\n",
        "\n",
        "for example in training_set:\n",
        "  num_training_examples += 1\n",
        "\n",
        "for example in validation_set:\n",
        "  num_validation_examples += 1\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "  return image, label\n",
        "\n",
        "\n",
        "IMAGE_RES = 299\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "URL = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "  input_shape=(IMAGE_RES, IMAGE_RES, 3),\n",
        "  trainable=False)\n",
        "\n",
        "model_inception = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "#model_inception.summary()\n",
        "\n",
        "\n",
        "model_inception.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 6\n",
        "\n",
        "history = model_inception.fit(train_batches,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches)\n",
        "\n",
        "#To display Accuracy Graphs\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpBm5w_cSSsh",
        "colab_type": "text"
      },
      "source": [
        "Fruits and Vegetables identification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g98HJIzDc5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d moltean/fruits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSU2JiK4jZ5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/fruits.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK_1s-WzoMGI",
        "colab_type": "code",
        "outputId": "46f2a09f-4cf5-49dd-a1e5-0d78fbf93482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"/tmp/fruits-360_dataset/fruits-360/Training\"\n",
        "training_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "train_generator = training_datagen.flow_from_directory(TRAINING_DIR,target_size=(100,100))\n",
        "\n",
        "\n",
        "VALIDATION_DIR = \"/tmp/fruits-360_dataset/fruits-360/Test\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,target_size=(100,100))\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Conv2D(16, (5,5), activation='relu', input_shape=(100, 100, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.05),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (5,5), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.05),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (5,5), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.05),\n",
        "\n",
        "   tf.keras.layers.Conv2D(128, (5,5), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.05),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.05),\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.05),\n",
        "\n",
        "    tf.keras.layers.Dense(120, activation='softmax')\n",
        "    \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60498 images belonging to 120 classes.\n",
            "Found 20622 images belonging to 120 classes.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 96, 96, 16)        1216      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 48, 48, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 48, 48, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 44, 44, 32)        12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 18, 18, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 128)         204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 1,088,792\n",
            "Trainable params: 1,088,792\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTBYdWvXK-0j",
        "colab_type": "code",
        "outputId": "05a36a91-8b30-4308-e6e1-169fd8fd2c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_generator, steps_per_epoch=1000 ,epochs=10,verbose=1 )\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.4045 - accuracy: 0.6106\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2304 - accuracy: 0.9260\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1451 - accuracy: 0.9538\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1265 - accuracy: 0.9629\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0768 - accuracy: 0.9766\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0944 - accuracy: 0.9735\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0773 - accuracy: 0.9772\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0761 - accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0659 - accuracy: 0.9823\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0707 - accuracy: 0.9812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ScdhJGISP90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate(validation_generator, verbose=1) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TszAQgA7_n5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"fruits_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}